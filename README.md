# Realtime-Emotion-Detection-model-using-CNN
## DESCRIPTION:
Our Approach is to detect the facial emotions using the Facial Action Units.
### FACS(Facial action coding system):
Facial Muscular Movements causing momentary changes in the facial expressions are termed as
AU(Action Units)
Facial Expressions are identified by using a single Action unit or a series of action units which are
associated with facial movements.
## DATASET DESCRIPTION:
### Dataset:
https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-
challenge/data
We are using 48x48 pixel grayscale images of faces
### Data Classified into -> seven categories:
1. 0=Angry
2. 1=Disgust
3. 2=Fear
4. 3=Happy
5. 4=Sad
6. 5=Surprise
7. 6=Neutral
Columns: "emotion" and "pixels"
No. of Classes: 7 (7 Emotions)
# TOOLS:
1. Keras
2. TensorFlow
3. OpenCV
4. Pandas
5. Numpy
6. Flask
7. Pillow
8. Gunicorn

Training Data: 28,709 samples.
Testing Data: 7178 samples

# PROJECT DIRCTORY: Real Time Emotion Detection from Facial Expression using CNN
Link: https://drive.google.com/drive/folders/161Yi5qqLs9jBsGJGNPY54eKlwmSE8KiJ
